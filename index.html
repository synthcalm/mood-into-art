<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Permissions-Policy" content="microphone=self">
    <meta http-equiv="Content-Security-Policy" content="default-src 'self' https://mood-into-art-backend.onrender.com; img-src 'self' blob: data: https:; media-src 'self' blob: mediastream:; connect-src 'self' https://mood-into-art-backend.onrender.com;">
    <title>MIA (Mood Into Art)</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            background-color: black;
            color: #00FF00;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }

        .container {
            width: 95%;
            max-width: 500px;
            padding: 20px;
            border: 2px solid #00FF00;
            border-radius: 12px;
            background-color: black;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        canvas#combinedCanvas {
            width: 100%;
            height: 80px;
            background-color: black;
            border: 1px solid #00FF00;
            margin-bottom: 10px;
        }

        .dot-alert {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background-color: red;
            animation: blink 1s infinite;
            display: none;
            margin-bottom: 10px;
        }

        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0; }
        }

        .footer-bar {
            display: flex;
            justify-content: space-between;
            align-items: center;
            width: 100%;
            font-size: 10pt;
            padding: 0 5px;
            margin-top: -10px;
            margin-bottom: 10px;
        }

        #dateDisplay {
            color: white;
        }

        #countdownDisplay {
            color: red;
        }

        textarea, select {
            width: 100%;
            padding: 10px;
            background-color: black;
            border: 2px solid #00FF00;
            color: white;
            margin-bottom: 10px;
            resize: vertical;
        }

        .button-group {
            width: 100%;
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 10px;
            margin-top: 10px;
        }

        .button {
            background-color: black;
            border: 2px solid #00FF00;
            color: #00FF00;
            padding: 10px;
            cursor: pointer;
            font-family: Arial, sans-serif;
        }

        .button.recording {
            background-color: #FFFF00;
            color: black;
        }

        #loadingIndicator {
            display: none;
            justify-content: center;
            gap: 4px;
            margin-top: 10px;
        }

        .dot {
            width: 4px;
            height: 4px;
            background-color: #00FF00;
            border-radius: 50%;
            opacity: 0;
            animation: blink 1.6s infinite;
        }

        .dot:nth-child(1) { animation-delay: 0s; }
        .dot:nth-child(2) { animation-delay: 0.4s; }
        .dot:nth-child(3) { animation-delay: 0.8s; }
        .dot:nth-child(4) { animation-delay: 1.2s; }

        #generatedImage {
            max-width: 100%;
            border: 1px solid #00FF00;
            margin-top: 20px;
            display: none;
        }

        #logHistory {
            width: 100%;
            font-size: 10px;
            margin-top: 20px;
            border-top: 1px dashed #00FF00;
            padding-top: 10px;
        }

        #permissionError {
            color: #FF6666;
            text-align: center;
            margin: 10px 0;
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <canvas id="combinedCanvas"></canvas>
        <div class="footer-bar">
            <div id="dateDisplay"></div>
            <div id="countdownDisplay">00:60:00</div>
        </div>
        <div class="dot-alert" id="redDot"></div>
        <div id="permissionError"></div>
        <textarea id="activityInput" rows="4" placeholder="Describe your mood..."></textarea>
        <select id="styleSelect">
            <option value="photo">Hyper-realistic Photo</option>
            <option value="anime">Japanese Anime</option>
            <option value="cubism">Cubism</option>
            <option value="surrealism">Surrealism</option>
            <option value="abstract">Abstract</option>
            <option value="steampunk">Steampunk</option>
            <option value="cyberpunk">Cyberpunk</option>
            <option value="watercolor">Watercolor</option>
            <option value="fantasy">Fantasy</option>
            <option value="none">No Image</option>
        </select>
        <div class="button-group">
            <button class="button" id="startVoice">Start Voice</button>
            <button class="button" id="redo">Redo</button>
            <button class="button" id="generate">Generate Image</button>
            <button class="button" id="saveImage">Save</button>
        </div>
        <div id="loadingIndicator">
            <div class="dot"></div>
            <div class="dot"></div>
            <div class="dot"></div>
            <div class="dot"></div>
        </div>
        <img id="generatedImage" />
        <div id="logHistory"></div>
    </div>
    <script>
        // Combined Canvas for Grid and Waveform
        const combinedCanvas = document.getElementById('combinedCanvas');
        const combinedCtx = combinedCanvas.getContext('2d');
        let audioContext, analyser, dataArray, source, animationId;
        let microphoneStream = null;

        // iOS audio fix - trigger audio context on first user interaction
        document.addEventListener('touchstart', initAudioContext, { once: true });
        document.addEventListener('click', initAudioContext, { once: true });

        function initAudioContext() {
            if (!audioContext) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                } catch (error) {
                    console.error("Error initializing AudioContext:", error);
                }
            }
            
            if (audioContext && audioContext.state !== 'running') {
                audioContext.resume().catch(err => console.error("Error resuming audio context:", err));
            }
        }

        function drawCombined() {
            combinedCanvas.width = combinedCanvas.clientWidth;
            combinedCanvas.height = combinedCanvas.clientHeight;
            const w = combinedCanvas.width;
            const h = combinedCanvas.height;
            combinedCtx.clearRect(0, 0, w, h);

            // Draw Grid
            combinedCtx.strokeStyle = 'rgba(0, 255, 255, 0.3)';
            combinedCtx.lineWidth = 0.3;
            for (let i = 0; i <= w; i += w / 20) {
                combinedCtx.beginPath();
                combinedCtx.moveTo(i, 0);
                combinedCtx.lineTo(i, h);
                combinedCtx.stroke();
            }
            for (let j = 0; j <= h; j += h / 12) {
                combinedCtx.beginPath();
                combinedCtx.moveTo(0, j);
                combinedCtx.lineTo(w, j);
                combinedCtx.stroke();
            }
            combinedCtx.strokeStyle = 'rgba(0, 255, 255, 0.5)';
            combinedCtx.lineWidth = 0.5;
            combinedCtx.beginPath();
            combinedCtx.moveTo(0, h / 2);
            combinedCtx.lineTo(w, h / 2);
            combinedCtx.stroke();

            // Draw Waveform
            if (analyser) {
                analyser.getByteTimeDomainData(dataArray);
                combinedCtx.strokeStyle = 'cyan';
                combinedCtx.lineWidth = 1;
                combinedCtx.beginPath();
                let sliceWidth = w / dataArray.length;
                let x = 0;
                for (let i = 0; i < dataArray.length; i++) {
                    let v = dataArray[i] / 128.0;
                    let y = v * h / 2;
                    if (i === 0) combinedCtx.moveTo(x, y);
                    else combinedCtx.lineTo(x, y);
                    x += sliceWidth;
                }
                combinedCtx.lineTo(w, h / 2);
                combinedCtx.stroke();
            }
            animationId = requestAnimationFrame(drawCombined);
        }

        async function startMic() {
            // Clear previous error messages
            document.getElementById('permissionError').style.display = 'none';
            document.getElementById('permissionError').textContent = '';

            try {
                // Ensure audio context is initialized
                initAudioContext();
                
                // Check for microphone permission first
                if (navigator.permissions && navigator.permissions.query) {
                    try {
                        const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
                        if (permissionStatus.state === 'denied') {
                            throw new Error("Microphone access is blocked in your browser settings");
                        }
                    } catch (permErr) {
                        console.warn("Could not check permissions:", permErr);
                        // Continue anyway, getUserMedia will handle permissions
                    }
                }

                // Get microphone stream with explicit constraints for iOS
                const constraints = {
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };
                
                microphoneStream = await navigator.mediaDevices.getUserMedia(constraints);
                
                // Initialize audio processing
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                
                if (audioContext.state !== 'running') {
                    await audioContext.resume();
                }

                source = audioContext.createMediaStreamSource(microphoneStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                dataArray = new Uint8Array(analyser.fftSize);
                source.connect(analyser);
                
                // Start visualization
                if (!animationId) {
                    drawCombined();
                }
                
                return true;
            } catch (error) {
                console.error("Error in startMic:", error);
                
                // Show user-friendly error message
                const errorElement = document.getElementById('permissionError');
                errorElement.style.display = 'block';
                
                if (error.name === 'NotAllowedError') {
                    errorElement.textContent = "Microphone access denied. Please allow microphone access in your browser settings.";
                } else if (error.name === 'NotFoundError') {
                    errorElement.textContent = "No microphone detected. Please connect a microphone and try again.";
                } else {
                    errorElement.textContent = "Error accessing microphone: " + error.message;
                }
                
                return false;
            }
        }

        function stopMic() {
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
                microphoneStream = null;
            }
            
            if (source) {
                source.disconnect();
                source = null;
            }
            
            if (analyser) {
                analyser = null;
            }
            
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            if (audioContext && audioContext.state === 'running') {
                audioContext.suspend().catch(err => console.error("Error suspending audio context:", err));
            }
        }

        // Initialize canvas on load and resize
        window.addEventListener('load', drawCombined);
        window.addEventListener('resize', drawCombined);

        // Date/Time
        function updateDateTime() {
            const now = new Date();
            const dateStr = `${now.getFullYear()}/${now.getMonth() + 1}/${now.getDate()}`;
            const timeStr = now.toLocaleTimeString();
            document.getElementById('dateDisplay').textContent = `${dateStr} ${timeStr}`;
        }
        setInterval(updateDateTime, 1000);
        updateDateTime();

        // Redo
        document.getElementById('redo').addEventListener('click', () => {
            document.getElementById('activityInput').value = '';
        });

        // Voice Recording and Transcription
        const startVoiceBtn = document.getElementById('startVoice');
        const activityInput = document.getElementById('activityInput');
        let recorder;
        let audioChunks = [];
        let isRecording = false;

        // Check if Web Speech API is available for fallback
        const webSpeechAPIAvailable = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;

        startVoiceBtn.addEventListener('click', async () => {
            // iOS Safari requires user interaction to start AudioContext
            initAudioContext();
            
            if (!isRecording) {
                // Try to use Web Speech API on Safari/iOS first if available
                if (webSpeechAPIAvailable && /iPad|iPhone|iPod/.test(navigator.userAgent)) {
                    startWebSpeechAPI();
                    return;
                }
                
                // Otherwise use MediaRecorder approach
                const micStarted = await startMic();
                if (!micStarted) return;
                
                try {
                    isRecording = true;
                    recorder = new MediaRecorder(microphoneStream, { 
                        mimeType: 'audio/webm;codecs=opus' 
                    });
                    
                    audioChunks = [];
                    recorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };

                    recorder.onstop = async () => {
                        isRecording = false;
                        startVoiceBtn.textContent = 'Start Voice';
                        startVoiceBtn.classList.remove('recording');
                        document.getElementById('redDot').style.display = 'none';
                        
                        if (audioChunks.length === 0) {
                            console.warn("No audio data recorded");
                            return;
                        }
                        
                        const audioBlob = new Blob(audioChunks, { type: recorder.mimeType });
                        await processAudioForTranscription(audioBlob);
                        
                        // Clean up
                        audioChunks = [];
                        stopMic();
                    };

                    recorder.start(100); // Collect data in 100ms chunks
                    startVoiceBtn.textContent = 'Stop Voice';
                    startVoiceBtn.classList.add('recording');
                    document.getElementById('redDot').style.display = 'block';
                } catch (error) {
                    isRecording = false;
                    console.error('Error starting recording:', error);
                    document.getElementById('permissionError').style.display = 'block';
                    document.getElementById('permissionError').textContent = 'Could not start recording: ' + error.message;
                }
            } else {
                // Stop recording
                if (recorder && recorder.state !== 'inactive') {
                    recorder.stop();
                }
                isRecording = false;
            }
        });

        // Web Speech API for iOS Safari
        function startWebSpeechAPI() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.error("Web Speech API not supported in this browser");
                return;
            }
            
            const recognition = new SpeechRecognition();
            recognition.lang = 'en-US';
            recognition.continuous = false;
            recognition.interimResults = false;
            
            // Show recording UI
            startVoiceBtn.textContent = 'Stop Voice';
            startVoiceBtn.classList.add('recording');
            document.getElementById('redDot').style.display = 'block';
            isRecording = true;
            
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                activityInput.value = transcript;
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                document.getElementById('permissionError').style.display = 'block';
                document.getElementById('permissionError').textContent = 'Speech recognition error: ' + event.error;
                resetRecordingUI();
            };
            
            recognition.onend = () => {
                resetRecordingUI();
            };
            
            try {
                recognition.start();
            } catch (err) {
                console.error("Could not start speech recognition:", err);
                resetRecordingUI();
            }
            
            // Update button to stop recognition
            startVoiceBtn.onclick = () => {
                if (isRecording) {
                    recognition.stop();
                }
            };
        }
        
        function resetRecordingUI() {
            startVoiceBtn.textContent = 'Start Voice';
            startVoiceBtn.classList.remove('recording');
            document.getElementById('redDot').style.display = 'none';
            isRecording = false;
            
            // Reset click handler to original function
            startVoiceBtn.onclick = startVoiceBtn.addEventListener;
        }

        // Process audio for backend transcription
        async function processAudioForTranscription(audioBlob) {
            const loadingIndicator = document.getElementById('loadingIndicator');
            loadingIndicator.style.display = 'flex';
            
            try {
                // Convert audio to base64
                const audioBuffer = await audioBlob.arrayBuffer();
                const audioBase64 = btoa(
                    new Uint8Array(audioBuffer)
                        .reduce((data, byte) => data + String.fromCharCode(byte), '')
                );
                
                // Send to backend for transcription
                const response = await fetch('https://mood-into-art-backend.onrender.com/transcribe', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ audioData: audioBase64 }),
                });
                
                const data = await response.json();
                if (data.transcription) {
                    activityInput.value = data.transcription;
                } else {
                    throw new Error(data.error || 'Unknown transcription error');
                }
            } catch (error) {
                console.error('Error transcribing:', error);
                document.getElementById('permissionError').style.display = 'block';
                document.getElementById('permissionError').textContent = 'Transcription failed: ' + error.message;
            } finally {
                loadingIndicator.style.display = 'none';
            }
        }

        // Generate with Stability AI via Render backend
        document.getElementById('generate').addEventListener('click', async () => {
            const input = document.getElementById('activityInput').value.trim();
            const style = document.getElementById('styleSelect').value;
            const loading = document.getElementById('loadingIndicator');
            const output = document.getElementById('generatedImage');
            const log = document.getElementById('logHistory');
            const errorElement = document.getElementById('permissionError');
            
            // Clear previous errors
            errorElement.style.display = 'none';
            
            if (!input || style === 'none') {
                errorElement.style.display = 'block';
                errorElement.textContent = 'Please enter a mood description and choose a style.';
                return;
            }
            
            const prompt = style === 'photo' ? `Hyper-realistic photo of ${input}` :
                style === 'anime' ? `Japanese anime illustration of ${input}` :
                `${input} in the style of ${style}`;
                
            loading.style.display = 'flex';
            output.style.display = 'none';
            
            try {
                const response = await fetch('https://mood-into-art-backend.onrender.com/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt })
                });
                
                if (!response.ok) {
                    throw new Error(`Server responded with status: ${response.status}`);
                }
                
                const data = await response.json();
                if (data.imageUrl) {
                    output.src = data.imageUrl;
                    output.style.display = 'block';
                    const timestamp = new Date().toLocaleString();
                    log.innerHTML += `<p>${timestamp}: ${prompt}</p>`;
                } else {
                    throw new Error(data.error || 'Unknown error');
                }
            } catch (err) {
                console.error('Generate image error:', err);
                errorElement.style.display = 'block';
                errorElement.textContent = 'Image generation failed: ' + err.message;
            } finally {
                loading.style.display = 'none';
            }
        });

        // Save Image
        document.getElementById('saveImage').addEventListener('click', () => {
            const output = document.getElementById('generatedImage');
            const log = document.getElementById('logHistory');
            const input = document.getElementById('activityInput').value.trim();
            const errorElement = document.getElementById('permissionError');
            
            if (output.src && output.style.display !== 'none') {
                try {
                    // For iOS Safari compatibility, use this approach
                    const a = document.createElement('a');
                    
                    // If on iOS, open in new tab as download might not work
                    if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
                        a.target = '_blank';
                    } else {
                        a.download = 'mood_into_art_image.png';
                    }
                    
                    a.href = output.src;
                    a.click();
                    
                    // Add to log
                    const timestamp = new Date().toLocaleString();
                    log.innerHTML += `<p>Saved - ${timestamp}: ${input}</p>`;
                } catch (err) {
                    console.error('Save image error:', err);
                    errorElement.style.display = 'block';
                    errorElement.textContent = 'Could not save image: ' + err.message;
                }
            } else {
                errorElement.style.display = 'block';
                errorElement.textContent = 'No image to save. Generate an image first.';
            }
        });
    </script>
</body>
</html>
